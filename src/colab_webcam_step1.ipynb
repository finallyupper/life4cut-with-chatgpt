{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzRKNe1iSlNW"
      },
      "source": [
        "# Google Colab: Access Webcam for Images and Video\n",
        "This notebook will go through how to access and run code on images and video taken using your webcam.  \n",
        "\n",
        "For this purpose of this tutorial we will be using OpenCV's Haar Cascade to do face detection on our Webcam image and video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Fj9YcAnsT4B_"
      },
      "outputs": [],
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6pCmkJrUC9g"
      },
      "source": [
        "## Helper Functions\n",
        "Below are a few helper function to make converting between different image data types and formats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "09b_0FAnUa9y"
      },
      "outputs": [],
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaZIOR4WaT64"
      },
      "source": [
        "## Haar Cascade Classifier\n",
        "For this tutorial we will run a simple object detection algorithm called Haar Cascade on our images and video fetched from our webcam. OpenCV has a pre-trained Haar Cascade face detection model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZpA68lTrcvZs"
      },
      "outputs": [],
      "source": [
        "# initialize the Haar Cascade face detection model\n",
        "face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRFoJo6QT94w"
      },
      "source": [
        "## Webcam Images\n",
        "Running code on images taken from webcam is fairly straight-forward. We will utilize code within Google Colab's **Code Snippets** that has a variety of useful code functions to perform various tasks.\n",
        "\n",
        "We will be using the code snippet for **Camera Capture** to utilize your computer's webcam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XwUtEojjnPRb"
      },
      "outputs": [],
      "source": [
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "\n",
        "  # get photo data\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  # get OpenCV format image\n",
        "  img = js_to_image(data)\n",
        "  # grayscale img\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "  print(gray.shape)\n",
        "  \n",
        "  cv2.imwrite(filename, img)\n",
        "\n",
        "  return filename, img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Qy3DKuU0PWTQ"
      },
      "outputs": [],
      "source": [
        "def capture_images(cnt):\n",
        "    try:\n",
        "        filename, img = take_photo(f'photo_{cnt}.jpg')\n",
        "        print('Saved to {}'.format(filename))\n",
        "\n",
        "        # Show the image which was just taken.\n",
        "        display(Image(filename))\n",
        "        return img\n",
        "    except Exception as err:\n",
        "        # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "        # grant the page permission to access it.\n",
        "        print(str(err))\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "LwpX49LwPWTQ"
      },
      "outputs": [],
      "source": [
        "def save_combined_images(images):\n",
        "    # 4개의 이미지를 2x2 배열로 보여줍니다\n",
        "    combined_image = np.zeros((images[0].shape[0] * 2, images[0].shape[1] * 2, 3), dtype=np.uint8)\n",
        "\n",
        "    combined_image[:images[0].shape[0], :images[0].shape[1]] = images[0]\n",
        "    combined_image[:images[1].shape[0], images[0].shape[1]:] = images[1]\n",
        "    combined_image[images[0].shape[0]:, :images[0].shape[1]] = images[2]\n",
        "    combined_image[images[0].shape[0]:, images[0].shape[1]:] = images[3]\n",
        "\n",
        "    # cv2.imshow('Captured Images', combined_image)\n",
        "    cv2.imwrite('/content/combine.jpg', combined_image)\n",
        "    # cv2.waitKey(0)\n",
        "    # cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "taMKGCE2PWTR"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    count = 4\n",
        "    images = []\n",
        "\n",
        "    for i in range(1, 5):\n",
        "        img = capture_images(i)\n",
        "        images.append(img)\n",
        "    # print(f'images : {images}')\n",
        "    if len(images) == 4:\n",
        "        save_combined_images(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYQWHq5sRW4h"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
